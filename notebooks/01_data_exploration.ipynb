{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0829b8ea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Data Exploration Notebook for Heuristic Analysis\n",
    "# Author: UWU/CST/21/083\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Load your dataset\n",
    "# Update this path to your actual dataset\n",
    "try:\n",
    "    df = pd.read_csv('data/raw/url_dataset.csv')\n",
    "    print(f\"Dataset loaded: {len(df)} URLs\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset not found. Creating sample data...\")\n",
    "    # Create sample data for testing\n",
    "    sample_urls = [\n",
    "        \"https://www.google.com/search?q=test\",\n",
    "        \"http://192.168.1.1/login.php\",\n",
    "        \"https://paypa1-login.secure.site.xyz/verify\",\n",
    "        \"http://bit.ly/3abc123\",\n",
    "        \"https://github.com/microsoft/vscode\",\n",
    "        \"http://free-gift.reward.top/get\",\n",
    "        \"https://my-bank-update.com/login/secure\",\n",
    "        \"http://legitimate-site.com/about\"\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame({'url': sample_urls, 'label': [0, 1, 1, 1, 0, 1, 1, 0]})\n",
    "    print(\"Sample dataset created\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\n=== Dataset Info ===\")\n",
    "print(df.info())\n",
    "print(\"\\n=== First 5 rows ===\")\n",
    "print(df.head())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\n=== Label Distribution ===\")\n",
    "label_counts = df['label'].value_counts()\n",
    "print(label_counts)\n",
    "print(f\"\\nBenign: {label_counts.get(0, 0)} URLs\")\n",
    "print(f\"Malicious: {label_counts.get(1, 0)} URLs\")\n",
    "\n",
    "# Heuristic Feature Extraction Functions\n",
    "def extract_features(url):\n",
    "    \"\"\"Extract basic heuristic features from URL\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Basic length features\n",
    "    features['url_length'] = len(url)\n",
    "    \n",
    "    # Parse URL\n",
    "    try:\n",
    "        parsed = urlparse(url)\n",
    "        hostname = parsed.hostname or ''\n",
    "        path = parsed.path or ''\n",
    "        \n",
    "        # Domain features\n",
    "        features['domain_length'] = len(hostname)\n",
    "        features['dot_count'] = hostname.count('.')\n",
    "        features['hyphen_count'] = hostname.count('-')\n",
    "        \n",
    "        # Check for IP\n",
    "        ip_pattern = r'\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b'\n",
    "        features['has_ip'] = 1 if re.search(ip_pattern, hostname) else 0\n",
    "        \n",
    "        # Suspicious TLDs\n",
    "        suspicious_tlds = ['.xyz', '.top', '.loan', '.tk', '.ml']\n",
    "        tld = '.' + hostname.split('.')[-1] if '.' in hostname else ''\n",
    "        features['suspicious_tld'] = 1 if tld in suspicious_tlds else 0\n",
    "        \n",
    "        # Suspicious keywords\n",
    "        suspicious_keywords = ['login', 'secure', 'verify', 'bank', 'account']\n",
    "        url_lower = url.lower()\n",
    "        features['suspicious_keyword'] = 1 if any(kw in url_lower for kw in suspicious_keywords) else 0\n",
    "        \n",
    "        # Special characters\n",
    "        features['has_special_chars'] = 1 if any(c in hostname for c in '@#$%&') else 0\n",
    "        \n",
    "        # Digit ratio\n",
    "        digits = re.findall(r'\\d', url)\n",
    "        features['digit_ratio'] = len(digits) / len(url) if url else 0\n",
    "        \n",
    "    except:\n",
    "        # If URL parsing fails, set default values\n",
    "        for key in ['domain_length', 'dot_count', 'hyphen_count', 'has_ip', \n",
    "                   'suspicious_tld', 'suspicious_keyword', 'has_special_chars', 'digit_ratio']:\n",
    "            features[key] = 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Apply feature extraction\n",
    "print(\"\\n=== Extracting Features ===\")\n",
    "features_list = []\n",
    "for url in df['url']:\n",
    "    features_list.append(extract_features(url))\n",
    "\n",
    "features_df = pd.DataFrame(features_list)\n",
    "df_features = pd.concat([df, features_df], axis=1)\n",
    "\n",
    "print(f\"Extracted {len(features_df.columns)} features\")\n",
    "print(\"\\nFeature columns:\", features_df.columns.tolist())\n",
    "\n",
    "# Visualizations\n",
    "print(\"\\n=== Creating Visualizations ===\")\n",
    "\n",
    "# 1. Feature distributions by label\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "feature_cols = ['url_length', 'domain_length', 'dot_count', 'hyphen_count', \n",
    "                'digit_ratio', 'has_ip', 'suspicious_tld', 'suspicious_keyword']\n",
    "\n",
    "for idx, feature in enumerate(feature_cols[:8]):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Separate by label\n",
    "    benign_data = df_features[df_features['label'] == 0][feature]\n",
    "    malicious_data = df_features[df_features['label'] == 1][feature]\n",
    "    \n",
    "    # Create box plot\n",
    "    data_to_plot = [benign_data.dropna(), malicious_data.dropna()]\n",
    "    ax.boxplot(data_to_plot, labels=['Benign', 'Malicious'])\n",
    "    ax.set_title(f'{feature} Distribution')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hide empty subplot\n",
    "axes[8].axis('off')\n",
    "\n",
    "plt.suptitle('Feature Distributions: Benign vs Malicious URLs', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/feature_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 2. Correlation heatmap\n",
    "print(\"\\n=== Feature Correlation ===\")\n",
    "correlation_matrix = df_features[feature_cols + ['label']].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 3. Feature importance analysis\n",
    "print(\"\\n=== Feature Importance Analysis ===\")\n",
    "\n",
    "# Calculate mean difference between malicious and benign\n",
    "feature_importance = {}\n",
    "for feature in feature_cols:\n",
    "    mean_benign = df_features[df_features['label'] == 0][feature].mean()\n",
    "    mean_malicious = df_features[df_features['label'] == 1][feature].mean()\n",
    "    diff = abs(mean_malicious - mean_benign)\n",
    "    feature_importance[feature] = diff\n",
    "\n",
    "# Sort by importance\n",
    "feature_importance_sorted = dict(sorted(feature_importance.items(), \n",
    "                                        key=lambda x: x[1], reverse=True))\n",
    "\n",
    "print(\"\\nFeature Importance (Difference between malicious and benign):\")\n",
    "for feature, importance in feature_importance_sorted.items():\n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "features = list(feature_importance_sorted.keys())\n",
    "importances = list(feature_importance_sorted.values())\n",
    "\n",
    "bars = plt.barh(features, importances, color='skyblue')\n",
    "plt.xlabel('Difference (Malicious - Benign)')\n",
    "plt.title('Feature Importance for Malicious URL Detection', fontsize=16)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(width + 0.001, bar.get_y() + bar.get_height()/2, \n",
    "             f'{width:.4f}', ha='left', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 4. Statistical analysis\n",
    "print(\"\\n=== Statistical Analysis ===\")\n",
    "\n",
    "for feature in feature_cols:\n",
    "    benign = df_features[df_features['label'] == 0][feature]\n",
    "    malicious = df_features[df_features['label'] == 1][feature]\n",
    "    \n",
    "    if len(benign) > 1 and len(malicious) > 1:\n",
    "        from scipy import stats\n",
    "        \n",
    "        # T-test\n",
    "        t_stat, p_value = stats.ttest_ind(benign, malicious, equal_var=False)\n",
    "        \n",
    "        print(f\"\\n{feature}:\")\n",
    "        print(f\"  Benign mean: {benign.mean():.4f}\")\n",
    "        print(f\"  Malicious mean: {malicious.mean():.4f}\")\n",
    "        print(f\"  T-statistic: {t_stat:.4f}\")\n",
    "        print(f\"  P-value: {p_value:.4f}\")\n",
    "        print(f\"  Significant: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "\n",
    "# Save processed data\n",
    "print(\"\\n=== Saving Processed Data ===\")\n",
    "df_features.to_csv('data/processed/urls_with_features.csv', index=False)\n",
    "print(\"Data saved to 'data/processed/urls_with_features.csv'\")\n",
    "\n",
    "print(\"\\n=== Analysis Complete ===\")\n",
    "print(f\"Total URLs analyzed: {len(df_features)}\")\n",
    "print(f\"Features extracted: {len(feature_cols)}\")\n",
    "print(f\"Visualizations saved to 'results/' folder\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
